{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using TensorFlow\n",
    "using CSV: read\n",
    "using Distributions: Normal\n",
    "using ProgressMeter: @showprogress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9×8127 Array{Float32,2}:\n",
       " -0.0082558   -0.0066579   -0.00292948  …  -0.00798948  -0.00878843\n",
       " -0.00532632  -0.00585895  -0.00292948     -0.00852212  -0.0111853 \n",
       " -0.00346211  -0.00452737  -0.00692422     -0.00878843  -0.0111853 \n",
       "  0.0215716    0.0149137    0.0218379       0.0218379    0.0218379 \n",
       "  0.0205063    0.0143811    0.0186421       0.021039     0.0221042 \n",
       "  0.0191748    0.0191748    0.0125169   …   0.0215716    0.0229032 \n",
       " -0.00186421  -0.00239685  -0.00692422     -0.00452737  -0.00479369\n",
       " -0.0015979   -0.0015979   -0.00905475     -0.00372843  -0.00292948\n",
       " -0.00292948  -0.00532632  -0.00878843     -0.00559264  -0.00213053"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing the data\n",
    "f = CSV.read(\"./gyroscope.csv\")\n",
    "\n",
    "T = length(f[:,11])\n",
    "Nw = 3                          # Window size\n",
    "Nc = 3                          # number of inputs\n",
    "Ncw = Nc * Nw                   # input size\n",
    "TNw = Int64(floor(T/Nw))        # number of time stamps\n",
    "\n",
    "dim1 =  Int64(floor(Ncw / 2))\n",
    "dim2 =  Int64(floor(dim1 / 2))\n",
    "\n",
    "raw_train = Array{Float32, 2}(Nc,T)\n",
    "raw_train = f[:,11:13]\n",
    "\n",
    "s = Array{Float32, 2}(Ncw,TNw)\n",
    "for i=1:TNw\n",
    "    s[:,i] .= vec(convert(Array,f[Nw*(i-1)+1:Nw*i,11:13]))\n",
    "end\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function weight_variable(shape, λ=0.1, reg=nn.l2_loss)\n",
    "    W = Variable(map(Float64, rand(Normal(0, .01), shape...)))\n",
    "    # regularization term\n",
    "    wd = λ * reg(W)\n",
    "    TensorFlow.add_to_collection(:regularizers, wd)\n",
    "    return W\n",
    "end\n",
    "\n",
    "function bias_variable(shape)\n",
    "    b = Variable(fill(Float64(.1), shape...))\n",
    "    return b\n",
    "end\n",
    "\n",
    "# returns a tensor that computes the autoencoder output for a timestamp t of the input array s\n",
    "function autoencoder(input)\n",
    "    enc = nn.sigmoid(W2 * nn.sigmoid(W1 * input + b1) + b2)\n",
    "    TensorFlow.add_to_collection(:encoders, enc)\n",
    "    return nn.sigmoid(W1t * nn.sigmoid(W2t * enc + b3) + b4)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 17:12:30.510308: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorFlow.Variables.Variable{Float64}(<Tensor node_6:1 shape=(9, 1) dtype=Float64>, <Tensor node_6/Assign:1 shape=unknown dtype=Float64>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "sess = Session(g)\n",
    "\n",
    "@tf begin\n",
    "    \n",
    "    x = placeholder(Float64, shape=[Ncw, 1])\n",
    "        \n",
    "    W1 = weight_variable([dim1, Ncw])\n",
    "    b1 = bias_variable([dim1, 1])\n",
    "\n",
    "    W2 = weight_variable([dim2, dim1])\n",
    "    b2 = bias_variable([dim2, 1])\n",
    "\n",
    "    # this is a tied weight\n",
    "    W2t = transpose(W2)\n",
    "    b3 = bias_variable([dim1, 1])\n",
    "\n",
    "    # this is a tied weight too\n",
    "    W1t = transpose(W1)\n",
    "    b4 = bias_variable([Ncw, 1])\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"./checkpoints/tensorflow\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize input as a matrix; passing vectors does not work\n",
    "input = Array{Any, 2}(Ncw,1)\n",
    "\n",
    "@tf begin\n",
    "    data = constant(s)\n",
    "\n",
    "    # iterate over all time windows\n",
    "    @showprogress for i=1:5 #TNw\n",
    "        # input is the i-th column of the data\n",
    "        input = slice(data,[1,i],[Ncw,1])\n",
    "        TensorFlow.add_to_collection(:losses, reduce_mean((autoencoder(input) - input)^2 ))\n",
    "    end\n",
    "    # add MSE and regularization loss for total loss\n",
    "    loss = reduce_sum(stack(get_collection(:losses))) + reduce_sum(stack(get_collection(:regularizers)))  \n",
    "    \n",
    "    \n",
    "    # iterate over all time windows again; calling get_collection before a collection has been\n",
    "    # populated does not give a reference to the Array that will be populated by add_to_collection\n",
    "    code = get_collection(:encoders)\n",
    "    @showprogress for i=2:5 #TNw\n",
    "        TensorFlow.add_to_collection(:dists, nn.l2_loss(code[i]-code[i-1])/sqrt(multiply(nn.l2_loss(code[i]),nn.l2_loss(code[i-1]))))\n",
    "    end  \n",
    "    # concatenate encoder outputs to build the code\n",
    "    dist = stack(get_collection(:dists))'\n",
    "    \n",
    "    opt = train.AdamOptimizer(1e-4)\n",
    "    optimizer = train.minimize(opt, loss)\n",
    "    \n",
    "    saver = train.Saver()\n",
    "    save_path = \"./checkpoints/tensorflow\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train new network\n",
    "run(sess, global_variables_initializer())\n",
    "\n",
    "emax = 1e4\n",
    "@showprogress for epoch=1:emax\n",
    "    cur_loss, _ = run(sess, (loss, optimizer))\n",
    "    if epoch%(emax/10) == 0\n",
    "        info(\"\\nepoch: $epoch | current loss: $cur_loss\\n\")\n",
    "    end\n",
    "end\n",
    "\n",
    "train.save(saver, sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mepoch:  1000 | elapsed time:    1.18 seconds | loss: 0.243071 | accuracy: not implemented\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mepoch:  2000 | elapsed time:    2.27 seconds | loss: 0.216937 | accuracy: not implemented\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mepoch:  3000 | elapsed time:    3.33 seconds | loss: 0.193763 | accuracy: not implemented\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mepoch:  4000 | elapsed time:    4.40 seconds | loss: 0.173015 | accuracy: not implemented\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mepoch:  5000 | elapsed time:    5.44 seconds | loss: 0.154339 | accuracy: not implemented\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mepoch:  6000 | elapsed time:    6.48 seconds | loss: 0.137487 | accuracy: not implemented\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mepoch:  7000 | elapsed time:    7.54 seconds | loss: 0.122275 | accuracy: not implemented\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mepoch:  8000 | elapsed time:    8.60 seconds | loss: 0.108548 | accuracy: not implemented\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mepoch:  9000 | elapsed time:    9.63 seconds | loss: 0.096177 | accuracy: not implemented\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mepoch: 10000 | elapsed time:   10.69 seconds | loss: 0.085044 | accuracy: not implemented\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "# reuse weights from a previously stored network\n",
    "run(sess, global_variables_initializer())\n",
    "train.restore(saver, sess, save_path)\n",
    "\n",
    "emax = Int32(1e4)\n",
    "elapsed = 0; tic()\n",
    "for epoch=1:emax\n",
    "    cur_loss, _ = run(sess, (loss, optimizer))\n",
    "    cur_loss = Float32(cur_loss)\n",
    "    if epoch%(emax/10) == 0\n",
    "        elapsed += toq(); tic()\n",
    "        info(\"epoch: $(@sprintf(\"%5i\", epoch)) | elapsed time: $(@sprintf(\"%6.1f\", elapsed)) seconds | loss: $(@sprintf(\"%.6f\", cur_loss)) | accuracy: not implemented\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 3.5845e-12 \n",
       " 8.58657e-13\n",
       " 3.47217e-11\n",
       " 2.12193e-11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(sess,dist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.3",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
