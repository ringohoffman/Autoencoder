{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using TensorFlow\n",
    "using CSV: read\n",
    "using Distributions: Normal\n",
    "using ProgressMeter: @showprogress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9×8127 Array{Float32,2}:\n",
       " -0.0082558   -0.0066579   -0.00292948  …  -0.00798948  -0.00878843\n",
       " -0.00532632  -0.00585895  -0.00292948     -0.00852212  -0.0111853 \n",
       " -0.00346211  -0.00452737  -0.00692422     -0.00878843  -0.0111853 \n",
       "  0.0215716    0.0149137    0.0218379       0.0218379    0.0218379 \n",
       "  0.0205063    0.0143811    0.0186421       0.021039     0.0221042 \n",
       "  0.0191748    0.0191748    0.0125169   …   0.0215716    0.0229032 \n",
       " -0.00186421  -0.00239685  -0.00692422     -0.00452737  -0.00479369\n",
       " -0.0015979   -0.0015979   -0.00905475     -0.00372843  -0.00292948\n",
       " -0.00292948  -0.00532632  -0.00878843     -0.00559264  -0.00213053"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing the data\n",
    "f = CSV.read(\"./gyroscope.csv\")\n",
    "\n",
    "T = length(f[:,11])\n",
    "# T = 24382\n",
    "Nw = 3                       # Window size\n",
    "Nc = 3                       # number of inputs\n",
    "Ncw = Nc * Nw                # input size\n",
    "TNw = Int64(floor(T/Nw))\n",
    "\n",
    "dim1 =  Int64(floor(Ncw / 2))\n",
    "dim2 =  Int64(floor(dim1 / 2))\n",
    "\n",
    "raw_train = Array{Float32, 2}(Nc,T)\n",
    "raw_train = f[:,11:13]\n",
    "\n",
    "s = Array{Float32, 2}(Ncw,TNw)\n",
    "for i=1:TNw\n",
    "    s[:,i] .= vec(convert(Array,f[Nw*(i-1)+1:Nw*i,11:13]))\n",
    "end\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function weight_variable(shape, λ=0.1, reg=nn.l2_loss)\n",
    "    W = Variable(map(Float64, rand(Normal(0, .01), shape...)))\n",
    "    # regularization term\n",
    "    wd = λ * reg(W)\n",
    "    TensorFlow.add_to_collection(:regularizers, wd)\n",
    "    return W\n",
    "end\n",
    "\n",
    "function bias_variable(shape)\n",
    "    initial = fill(Float64(.1), shape...)\n",
    "    return Variable(initial)\n",
    "end\n",
    "\n",
    "# returns a tensor that computes the autoencoder output for a timestamp t of the input array s\n",
    "function autoencoder(input)\n",
    "    enc = W2 * nn.sigmoid(W1 * input + b1) + b2\n",
    "    TensorFlow.add_to_collection(:encoders, enc)\n",
    "    return nn.sigmoid(W1t * nn.sigmoid(W2t * nn.sigmoid(enc) + b3) + b4)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-08 16:15:35.854023: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorFlow.Variables.Variable{Float64}(<Tensor node_6:1 shape=(9, 1) dtype=Float64>, <Tensor node_6/Assign:1 shape=unknown dtype=Float64>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "sess = Session(g)\n",
    "\n",
    "@tf begin\n",
    "    \n",
    "    x = placeholder(Float64, shape=[Ncw, 1])\n",
    "        \n",
    "    W1 = weight_variable([dim1, Ncw])\n",
    "    b1 = bias_variable([dim1, 1])\n",
    "\n",
    "    W2 = weight_variable([dim2, dim1])\n",
    "    b2 = bias_variable([dim2, 1])\n",
    "\n",
    "    # this is a tied weight\n",
    "    W2t = transpose(W2)\n",
    "    b3 = bias_variable([dim1, 1])\n",
    "\n",
    "    # this is a tied weight too\n",
    "    W1t = transpose(W1)\n",
    "    b4 = bias_variable([Ncw, 1])\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mTensorflow error: Status: Value for attr 'N' of 0 must be at least minimum 1\n\t; NodeDef: Pack_2 = Pack[N=0, axis=0](); Op<name=Pack; signature=values:N*T -> output:T; attr=N:int,min=1; attr=T:type; attr=axis:int,default=0>\n\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mTensorflow error: Status: Value for attr 'N' of 0 must be at least minimum 1\n\t; NodeDef: Pack_2 = Pack[N=0, axis=0](); Op<name=Pack; signature=values:N*T -> output:T; attr=N:int,min=1; attr=T:type; attr=axis:int,default=0>\n\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1mcheck_status\u001b[22m\u001b[22m at \u001b[1m/Users/ringohoffman/.julia/v0.6/TensorFlow/src/core.jl:447\u001b[22m\u001b[22m [inlined]",
      " [2] \u001b[1mTensorFlow.Operation\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.NodeDescription\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/ringohoffman/.julia/v0.6/TensorFlow/src/core.jl:1076\u001b[22m\u001b[22m",
      " [3] \u001b[1m#pack#232\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Void, ::Void, ::Void, ::Function, ::Array{Any,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/ringohoffman/.julia/v0.6/TensorFlow/src/ops/imported_ops.jl:2611\u001b[22m\u001b[22m",
      " [4] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m./In[5]:14\u001b[22m\u001b[22m [inlined]",
      " [5] \u001b[1manonymous\u001b[22m\u001b[22m at \u001b[1m./<missing>:?\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "input = Array{Any, 2}(Ncw,1)\n",
    "\n",
    "@tf begin\n",
    "    data = constant(s)\n",
    "    \n",
    "    # iterate over all time windows\n",
    "    for i=1:5#TNw\n",
    "        # input is the i-th column of the data\n",
    "        input = slice(data,[1,i],[Ncw,1])\n",
    "        TensorFlow.add_to_collection(:losses, reduce_mean((autoencoder(input) - input)^2 ))\n",
    "    end\n",
    "    \n",
    "    # add MSE and regularization loss for total loss\n",
    "    loss = reduce_sum(stack(get_collection(:losses))) + reduce_sum(stack(get_collection(:regularizations)))\n",
    "    # concatenate encoder outputs to build the code\n",
    "    code = concat(get_collection(:encoders), 2)\n",
    "    optimizer = train.minimize(train.AdamOptimizer(1e-4), loss)\n",
    "end\n",
    "\n",
    "run(sess, global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@showprogress for epoch=1:1e3\n",
    "    cur_loss, _ = run(sess, (loss, optimizer))\n",
    "    if epoch%100 == 0\n",
    "        info(cur_loss)\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.3",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
