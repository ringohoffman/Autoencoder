{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux.Tracker\n",
    "using CSV: read\n",
    "using BSON: @load, @save\n",
    "using Missings: ismissing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the data\n",
    "f = CSV.read(\"./sandp500/all_stocks_5yr.csv\")\n",
    "\n",
    "T = 1259\n",
    "Nw = 25                      # Window size\n",
    "num = 1                      # starting number of data points\n",
    "Nc = 0                       # number of companies\n",
    "prev = f[1,7]                # first company in list\n",
    "list = Array{Int64,1}(469)   # list of starting indicies of companies with 1259 data points\n",
    "\n",
    "for i=2:length(f[:,7])\n",
    "    \n",
    "    # take average of adjacent values to account for missing values\n",
    "    if ismissing(f[i,2]) && (f[i-1,7] == f[i+1,7])\n",
    "        f[i,2] = (f[i-1,2] + f[i+1,2])\n",
    "    end\n",
    "    \n",
    "    # count number of data points per company, adding beginning index\n",
    "    # of each to list if number of data points == 1259\n",
    "    if f[i,7] != prev\n",
    "        prev = f[i,7]\n",
    "        if num == 1259\n",
    "            Nc += 1\n",
    "            list[Nc] = i-num\n",
    "        end     \n",
    "        num = 1\n",
    "    else\n",
    "        num += 1\n",
    "    end\n",
    "end\n",
    "\n",
    "# place each company with 1259 data points into its own colum\n",
    "s_raw = Array{Float64, 2}(T,Nc)\n",
    "for i=1:Nc\n",
    "    s_raw[:,i] .= f[list[i]:list[i]+T-1,2]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat data for input to the model\n",
    "t = Int64(floor(T/Nw))\n",
    "\n",
    "s = Array{Float64, 2}(Nc*Nw,t)\n",
    "for i=1:t\n",
    "    s[:,i] .= vec(s_raw[Nw*(i-1)+1:Nw*i,:])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function create()\n",
    "    # common sub-expressions\n",
    "    Ncw = Nc * Nw\n",
    "    df1 = Int64(floor(Ncw / 3))\n",
    "    df2 = Int64(floor(df1 / 6))\n",
    "    \n",
    "    # encoder weights saved to use in decoder weight creation\n",
    "    W1a = Flux.glorot_uniform(df1,Ncw)\n",
    "    W2a = Flux.glorot_uniform(df2,df1)\n",
    "    \n",
    "    layer1 = Dense(param(W1a),param(rand(df1)),relu)\n",
    "    layer2 = Dense(param(W2a),param(rand(df2)),relu)\n",
    "    layer3 = Dense(param(W2a'),param(rand(df1)),relu)\n",
    "    layer4 = Dense(param(W1a'),param(rand(Ncw)),relu)\n",
    "    \n",
    "    m = Chain(layer1,layer2,layer3,layer4)\n",
    "    return m\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function loss(model,s,λ)\n",
    "    # loss is the mean squared error of the input with the output\n",
    "    l = 0\n",
    "    for i = 1:t\n",
    "        l += Flux.mse(s[:,i],model(s[:,i]))\n",
    "    end\n",
    "    # regularization term\n",
    "    penalty() = λ * (vecnorm(model.layers[1].W)^2 + vecnorm(model.layers[2].W)^ 2)\n",
    "    return l + penalty()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function update(model, α)\n",
    "    # update weights\n",
    "    model.layers[1].W.data .-= α * (model.layers[1].W.grad  + model.layers[4].W.grad')\n",
    "    model.layers[4].W.data .-= α * (model.layers[1].W.grad' + model.layers[4].W.grad )\n",
    "    model.layers[2].W.data .-= α * (model.layers[2].W.grad  + model.layers[3].W.grad') \n",
    "    model.layers[3].W.data .-= α * (model.layers[2].W.grad' + model.layers[3].W.grad )\n",
    "    \n",
    "    # update biases\n",
    "    model.layers[1].b.data .-= α * model.layers[1].b.grad\n",
    "    model.layers[2].b.data .-= α * model.layers[2].b.grad\n",
    "    model.layers[3].b.data .-= α * model.layers[3].b.grad\n",
    "    model.layers[4].b.data .-= α * model.layers[4].b.grad\n",
    "    \n",
    "    # for each layer\n",
    "    for layer in model.layers\n",
    "        # set grads to 0\n",
    "        layer.W.grad .= 0\n",
    "        layer.b.grad .= 0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train(model, s, loss_f)\n",
    "    # calculate loss\n",
    "    l = loss(model, s, 0.1)\n",
    "    # calculate gradients\n",
    "    back!(l)\n",
    "    # perform updates\n",
    "    update(model, 0.1)\n",
    "    return l\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create()\n",
    "\n",
    "for i=1:2\n",
    "    l = train(model, s, loss)\n",
    "    if i%2==0\n",
    "        println(\"Iteration: $i\\n   loss: $l\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "weights = Tracker.data.(params(model))\n",
    "@save \"model.bson\" model\n",
    "@save \"model_weights.bson\" weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "@load \"model.bson\" model\n",
    "@load \"model_weights.bson\" weights\n",
    "Flux.loadparams!(model, weights)\n",
    "\n",
    "# test that model loaded corectly\n",
    "l = loss(model, s, 0.1)\n",
    "println(\"loss: $l\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.3",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
